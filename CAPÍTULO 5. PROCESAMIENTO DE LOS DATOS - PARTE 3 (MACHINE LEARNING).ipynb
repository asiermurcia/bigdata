{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAPÍTULO 5. PROCESAMIENTO DE LOS DATOS - PARTE 3 (MACHINE LEARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo el código expuesto forma parte del TFG: \"Diseño basado en Big Data para aplicación en ingeniería\", presentado en la ETSIDI de la Universidad Politécnica de Madrid, en junio de 2020.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo red neuronal para puerta XOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se carga el set de datos para el entrenamiento. En este caso, las 4 combinaciones posibles de una entrada XOR.\n",
    "training_data= np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
    "\n",
    "#Se carga la salida correcta de la puerta XOR\n",
    "target_data = np.array([[0],[1],[1],[0]]), \"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se construye el modelo\n",
    "\n",
    "model = Sequential() #Se genera el contenedor de la red neuronal\n",
    "model.add(Dense(16, input_dim=2, activation='relu')) #16 indica el número de neuronas seleccionadas\n",
    "model.add(Dense(1, activation='sigmoid')) #Se define la función de activación, en este caso, sigmoide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se entrena al modelo, en este caso aplicando como función de error el error cuadrático medio\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(training_data, target_data, epochs=1000) #el número de epochs define el número de iteraciones que se realizan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se evalua el modelo \n",
    "scores = model.evaluate(training_data, target_data)\n",
    " \n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print (model.predict(training_data).round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redes LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(4)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se definen los datos en variables\n",
    "df = df['Columna seleccionada']\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define el set de entrenamiento y de validacion indicando que fechas limitan cada uno. \n",
    "set_entrenamiento = df[:'2018-12-01']\n",
    "set_validacion = df['2018-12-01':]\n",
    "set_entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define el escalador que transformará los datos a valores entre 0 y 1. \n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(set_entrenamiento)\n",
    "set_entrenamiento = scaler.transform(set_entrenamiento)\n",
    "set_validacion = scaler.transform(set_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 12 #numero de datos de entrenamiento por cada dato de validación\n",
    "n_features = 1\n",
    "\n",
    "generator = TimeseriesGenerator(set_entrenamiento,set_entrenamiento,length=n_input,batch_size=6)\n",
    "\n",
    "model = Sequential() #contenedor de la red\n",
    "model.add(LSTM(300,activation='relu',input_shape=(n_input,n_features))) #300 indica el número de neuronas de la red LSTM\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(1)) #capa de salida\n",
    "model.compile(optimizer='adam',loss='mse') #entrenamiento metodo rmsprop = gradiente descendiente\n",
    "\n",
    "model.fit_generator(generator,epochs=1000) #funcion de error: error cuadratico medio. Lotes de 1000 ejemplo en este caso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez entrenada la red, se pasa a realizar el test de validación, para comprobar el error de la misma. \n",
    "\n",
    "pred_list = set_validacion\n",
    "pred_list = scaler.transform(pred_list)\n",
    "\n",
    "pred_list = []\n",
    "\n",
    "batch = set_entrenamiento[-n_input:].reshape((1,n_input,n_features)) \n",
    "\n",
    "for i in range(n_input):\n",
    "    pred_list.append(model.predict(batch)[0]) #normalizacion inversa de los datos, escala real\n",
    "    batch = np.append(batch[:,1:,:], [[pred_list[i]]],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Des-escalamos los valores\n",
    "\n",
    "df_predict = pd.DataFrame(scaler.inverse_transform(pred_list),index=df[-n_input:].index, columns=['Predicción'])\n",
    "\n",
    "df_test = pd.concat([df,df_predict],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.tail(12) #muestra los valores predecidos por pantalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizamos los resultados del entrenamiento en forma gráfica\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(df_test.index,df_test['nombre columna seleccionada'])\n",
    "plt.plot(df_test.index,df_test['Predicción'],color='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez entrenado el modelo, creamos lo valores futuros\n",
    "\n",
    "set_entrenamiento = df\n",
    "\n",
    "scaler.fit(set_entrenamiento)\n",
    "set_entrenamiento = scaler.transform(set_entrenamiento)\n",
    "\n",
    "n_input = 12\n",
    "n_features = 1\n",
    "\n",
    "generator = TimeseriesGenerator(set_entrenamiento,set_entrenamiento,length=n_input,batch_size=6)\n",
    "\n",
    "model.fit_generator(generator,epochs=1000)\n",
    "\n",
    "pred_list = []\n",
    "\n",
    "batch = set_entrenamiento[-n_input:].reshape((1,n_input,n_features))\n",
    "\n",
    "for i in range(n_input):\n",
    "    pred_list.append(model.predict(batch)[0])\n",
    "    batch = np.append(batch[:,1:,:], [[pred_list[i]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los añadimos a una nueva columna de nuestro Dataframe para que queden guardados\n",
    "\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "add_dates = [df.index[-1] + DateOffset(months=x) for x in range(0,13)]\n",
    "future_dates = pd.DataFrame(index=add_dates[1:],columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Des-escalamos los resultados\n",
    "\n",
    "df_predict = pd.DataFrame(scaler.inverse_transform(pred_list),\n",
    "                                 index=future_dates[-n_input:].index,columns=['Predicciones'])\n",
    "\n",
    "df_proj = pd.concat([df,df_predict],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizamos los resultados de forma gráfica\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_proj.index,df_proj['nombre columna seleccionada'])\n",
    "plt.plot(df_proj.index,df_proj['Predicciones'],color='r')\n",
    "plt.legend(loc='best',fontsize='large')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Todo el código expuesto forma parte del TFG: \"Diseño basado en Big Data para aplicación en ingeniería\", presentado en la ETSIDI de la Universidad Politécnica de Madrid, en junio de 2020.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
